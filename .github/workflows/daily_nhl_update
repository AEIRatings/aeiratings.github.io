name: Daily NHL Standings Update

on:
  schedule:
    # Runs once a day at 10:00 AM UTC, which is 6:00 AM Eastern Time (ET)
    - cron: '0 10 * * *' 
  
  # Also allow manual running via the GitHub Actions tab
  workflow_dispatch:

jobs:
  update-nhl-data:
    runs-on: ubuntu-latest
    
    # REQUIRED: Grant write permission for the GITHUB_TOKEN to allow the action to commit changes
    permissions:
      contents: write 

    steps:
      - name: Checkout Repository
        # Checks out your repository's code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }} 

      - name: Set up Python
        # Sets up the Python environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install Dependencies
        # Installs the necessary Python libraries (BeautifulSoup4 for web scraping)
        run: |
          python -m pip install --upgrade pip
          pip install beautifulsoup4

      - name: Scrape Data and Update CSV
        # Combines the curl download and Python execution
        run: |
          echo "Downloading NHL 2026 standings HTML..."
          # 1. Use curl to get the source HTML and save it locally as nhl2026.html
          curl -sL "https://www.hockey-reference.com/leagues/NHL_2026.html" -o "nhl2026.html"

          # 2. Execute the Python script to scrape, merge with data/nhl.csv, and write back.
          echo "Running Python scraper and merging data..."
          python NHL_Standings_Scraper.py
        
      - name: Commit and Push Changes
        # Automatically commits and pushes the updated data/nhl.csv file
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "ðŸ¤– Daily NHL Standings update: Points from Hockey-Reference"
          # Specify the files to commit: the updated CSV and the downloaded HTML file
          file_pattern: |
            data/nhl.csv
            nhl2026.html
          commit_author: 'GitHub Actions Bot <action@github.com>'
          skip_dirty_check: true
